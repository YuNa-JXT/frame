import streamlit as st
import pandas as pd
import numpy as np
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings

warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# --- é…ç½®ç±» ---
class Config:
    """ç³»ç»Ÿé…ç½®ç±»"""
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    SUPPORTED_FORMATS = ["csv", "xlsx", "xls"]
    DATE_FORMATS = ["%Y-%m-%d", "%d/%m/%Y", "%m/%d/%Y", "%Y/%m/%d"]
    MIN_DATA_POINTS = 30
    MAX_DATA_POINTS = 10000
    OUTLIER_THRESHOLD = 3
    SEASONALITY_MIN_PERIODS = 730  # 2å¹´æ•°æ®æ‰èƒ½å¯é æ£€æµ‹å­£èŠ‚æ€§


# --- æ•°æ®éªŒè¯å’Œå¤„ç†ç±» ---
class DataValidator:
    """æ•°æ®éªŒè¯å’Œæ¸…æ´—ç±»"""

    @staticmethod
    def validate_file_size(file) -> bool:
        """éªŒè¯æ–‡ä»¶å¤§å°"""
        if hasattr(file, 'size') and file.size > Config.MAX_FILE_SIZE:
            return False
        return True

    @staticmethod
    def parse_date_column(df: pd.DataFrame, date_col: str = 'Date') -> pd.DataFrame:
        """æ™ºèƒ½è§£ææ—¥æœŸåˆ—"""
        if date_col not in df.columns:
            raise ValueError(f"æ•°æ®ä¸­æœªæ‰¾åˆ°'{date_col}'åˆ—")

        # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
        for date_format in Config.DATE_FORMATS:
            try:
                df[date_col] = pd.to_datetime(df[date_col], format=date_format)
                return df
            except:
                continue

        # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œå°è¯•è‡ªåŠ¨æ¨æ–­
        try:
            df[date_col] = pd.to_datetime(df[date_col], infer_datetime_format=True)
            return df
        except:
            raise ValueError("æ— æ³•è§£ææ—¥æœŸæ ¼å¼ï¼Œè¯·ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®")

    @staticmethod
    def validate_data_structure(df: pd.DataFrame) -> Tuple[bool, str]:
        """éªŒè¯æ•°æ®ç»“æ„"""
        required_cols = ['Date', 'Cases']
        missing_cols = [col for col in required_cols if col not in df.columns]

        if missing_cols:
            return False, f"ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}"

        if len(df) < Config.MIN_DATA_POINTS:
            return False, f"æ•°æ®ç‚¹æ•°é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦{Config.MIN_DATA_POINTS}ä¸ªæ•°æ®ç‚¹"

        if len(df) > Config.MAX_DATA_POINTS:
            return False, f"æ•°æ®ç‚¹æ•°é‡è¿‡å¤šï¼Œæœ€å¤šæ”¯æŒ{Config.MAX_DATA_POINTS}ä¸ªæ•°æ®ç‚¹"

        # æ£€æŸ¥Casesåˆ—æ˜¯å¦ä¸ºæ•°å€¼å‹
        if not pd.api.types.is_numeric_dtype(df['Cases']):
            return False, "Casesåˆ—å¿…é¡»ä¸ºæ•°å€¼å‹æ•°æ®"

        # æ£€æŸ¥æ˜¯å¦æœ‰è´Ÿå€¼
        if (df['Cases'] < 0).any():
            return False, "Casesåˆ—ä¸èƒ½åŒ…å«è´Ÿå€¼"

        return True, "æ•°æ®éªŒè¯é€šè¿‡"

    @staticmethod
    def clean_data(df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—"""
        # ç§»é™¤é‡å¤æ—¥æœŸ
        df = df.drop_duplicates(subset=['Date'])

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('Date')

        # å¤„ç†ç¼ºå¤±å€¼
        df['Cases'] = df['Cases'].fillna(df['Cases'].median())

        # é‡ç½®ç´¢å¼•
        df = df.reset_index(drop=True)

        return df


# --- åç«¯åˆ†æç±» ---
class TimeSeriesAnalyzer:
    """æ—¶é—´åºåˆ—åˆ†æç±»"""

    def __init__(self):
        self.results = {}

    def analyze_stationarity(self, data: pd.Series) -> Dict:
        """å¹³ç¨³æ€§æ£€æµ‹"""
        try:
            from statsmodels.tsa.stattools import adfuller
            result = adfuller(data.dropna())

            return {
                'adf_statistic': result[0],
                'p_value': result[1],
                'critical_values': result[4],
                'is_stationary': result[1] < 0.05,
                'interpretation': 'åºåˆ—å¹³ç¨³' if result[1] < 0.05 else 'åºåˆ—éå¹³ç¨³'
            }
        except Exception as e:
            logger.error(f"å¹³ç¨³æ€§æ£€æµ‹å¤±è´¥: {e}")
            return {
                'error': str(e),
                'is_stationary': False,
                'interpretation': 'æ— æ³•è¿›è¡Œå¹³ç¨³æ€§æ£€æµ‹'
            }

    def analyze_seasonality(self, data: pd.Series) -> Dict:
        """å­£èŠ‚æ€§æ£€æµ‹"""
        try:
            if len(data) < Config.SEASONALITY_MIN_PERIODS:
                return {
                    'has_seasonality': False,
                    'warning': f"æ•°æ®é•¿åº¦ä¸è¶³{Config.SEASONALITY_MIN_PERIODS}å¤©ï¼Œæ— æ³•å¯é æ£€æµ‹å­£èŠ‚æ€§"
                }

            from statsmodels.tsa.seasonal import seasonal_decompose
            decomposition = seasonal_decompose(
                data.dropna(),
                model='additive',
                period=365,
                extrapolate_trend='freq'
            )

            # è®¡ç®—å­£èŠ‚æ€§å¼ºåº¦
            seasonal_strength = decomposition.seasonal.var() / data.var()

            return {
                'has_seasonality': seasonal_strength > 0.01,
                'seasonal_strength': seasonal_strength,
                'interpretation': 'å­˜åœ¨æ˜æ˜¾å­£èŠ‚æ€§' if seasonal_strength > 0.01 else 'å­£èŠ‚æ€§ä¸æ˜æ˜¾'
            }
        except Exception as e:
            logger.error(f"å­£èŠ‚æ€§æ£€æµ‹å¤±è´¥: {e}")
            return {
                'error': str(e),
                'has_seasonality': False,
                'interpretation': 'æ— æ³•è¿›è¡Œå­£èŠ‚æ€§æ£€æµ‹'
            }

    def detect_outliers(self, data: pd.Series) -> Dict:
        """å¼‚å¸¸å€¼æ£€æµ‹"""
        try:
            # Z-scoreæ–¹æ³•
            z_scores = np.abs((data - data.mean()) / data.std())
            outliers_mask = z_scores > Config.OUTLIER_THRESHOLD
            outliers = data[outliers_mask]

            # IQRæ–¹æ³•ä½œä¸ºè¡¥å……
            Q1 = data.quantile(0.25)
            Q3 = data.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            iqr_outliers = data[(data < lower_bound) | (data > upper_bound)]

            return {
                'num_outliers': len(outliers),
                'outlier_percentage': len(outliers) / len(data) * 100,
                'has_bursts': len(outliers) > 0,
                'outlier_indices': outliers.index.tolist(),
                'iqr_outliers': len(iqr_outliers),
                'interpretation': f'æ£€æµ‹åˆ°{len(outliers)}ä¸ªå¼‚å¸¸å€¼' if len(outliers) > 0 else 'æœªæ£€æµ‹åˆ°æ˜æ˜¾å¼‚å¸¸å€¼'
            }
        except Exception as e:
            logger.error(f"å¼‚å¸¸å€¼æ£€æµ‹å¤±è´¥: {e}")
            return {
                'error': str(e),
                'has_bursts': False,
                'interpretation': 'æ— æ³•è¿›è¡Œå¼‚å¸¸å€¼æ£€æµ‹'
            }

    def comprehensive_analysis(self, df: pd.DataFrame) -> Dict:
        """ç»¼åˆåˆ†æ"""
        try:
            data = df.set_index('Date')['Cases']

            results = {
                'data_info': {
                    'total_points': len(data),
                    'date_range': f"{data.index.min().strftime('%Y-%m-%d')} åˆ° {data.index.max().strftime('%Y-%m-%d')}",
                    'mean_cases': data.mean(),
                    'std_cases': data.std(),
                    'min_cases': data.min(),
                    'max_cases': data.max()
                }
            }

            # åˆ†åˆ«è¿›è¡Œå„é¡¹åˆ†æ
            results['stationarity'] = self.analyze_stationarity(data)
            results['seasonality'] = self.analyze_seasonality(data)
            results['outliers'] = self.detect_outliers(data)

            # ç”Ÿæˆç»¼åˆç»“è®º
            results['summary'] = self._generate_summary(results)

            return results

        except Exception as e:
            logger.error(f"ç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}

    def _generate_summary(self, results: Dict) -> str:
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        summary_parts = []

        if results.get('stationarity', {}).get('is_stationary'):
            summary_parts.append("æ•°æ®åºåˆ—å¹³ç¨³")
        else:
            summary_parts.append("æ•°æ®åºåˆ—éå¹³ç¨³")

        if results.get('seasonality', {}).get('has_seasonality'):
            summary_parts.append("å­˜åœ¨å­£èŠ‚æ€§æ¨¡å¼")
        else:
            summary_parts.append("æ— æ˜æ˜¾å­£èŠ‚æ€§")

        outlier_count = results.get('outliers', {}).get('num_outliers', 0)
        if outlier_count > 0:
            summary_parts.append(f"æ£€æµ‹åˆ°{outlier_count}ä¸ªå¼‚å¸¸å€¼")
        else:
            summary_parts.append("æ— æ˜æ˜¾å¼‚å¸¸å€¼")

        return "ï¼Œ".join(summary_parts)


# --- æ¨¡å‹æ¨èç±» ---
class ModelRecommender:
    """æ¨¡å‹æ¨èç³»ç»Ÿ"""

    def __init__(self):
        self.model_info = {
            'ARIMA': {
                'description': 'ARIMAæ¨¡å‹é€‚ç”¨äºå¹³ç¨³æ—¶é—´åºåˆ—',
                'pros': ['ç»å…¸å¯é ', 'å‚æ•°å¯è§£é‡Š', 'é¢„æµ‹ç½®ä¿¡åŒºé—´'],
                'cons': ['è¦æ±‚æ•°æ®å¹³ç¨³', 'ä¸é€‚åˆå¤„ç†å¤æ‚éçº¿æ€§å…³ç³»'],
                'best_for': 'å¹³ç¨³æ•°æ®ï¼Œæ— å­£èŠ‚æ€§ï¼Œæ— çªå‘æ€§'
            },
            'SARIMA': {
                'description': 'å­£èŠ‚æ€§ARIMAæ¨¡å‹',
                'pros': ['å¤„ç†å­£èŠ‚æ€§', 'ç†è®ºåŸºç¡€æ‰å®', 'é¢„æµ‹ç½®ä¿¡åŒºé—´'],
                'cons': ['å‚æ•°è°ƒä¼˜å¤æ‚', 'è®¡ç®—ç›¸å¯¹è¾ƒæ…¢'],
                'best_for': 'æœ‰å­£èŠ‚æ€§çš„å¹³ç¨³æˆ–éå¹³ç¨³æ•°æ®'
            },
            'Prophet': {
                'description': 'Facebookå¼€å‘çš„æ—¶é—´åºåˆ—é¢„æµ‹å·¥å…·',
                'pros': ['è‡ªåŠ¨å¤„ç†å­£èŠ‚æ€§', 'å¤„ç†ç¼ºå¤±å€¼', 'å¯¹å¼‚å¸¸å€¼é²æ£’'],
                'cons': ['é»‘ç›’æ¨¡å‹', 'å¯¹çŸ­æœŸæ•°æ®æ•ˆæœä¸€èˆ¬'],
                'best_for': 'é•¿æœŸæ•°æ®ï¼Œæœ‰å­£èŠ‚æ€§ï¼Œå­˜åœ¨å¼‚å¸¸å€¼'
            },
            'LSTM': {
                'description': 'é•¿çŸ­æœŸè®°å¿†ç¥ç»ç½‘ç»œ',
                'pros': ['æ•æ‰å¤æ‚æ¨¡å¼', 'å¤„ç†é•¿æœŸä¾èµ–', 'é€‚åº”æ€§å¼º'],
                'cons': ['éœ€è¦å¤§é‡æ•°æ®', 'è®­ç»ƒæ—¶é—´é•¿', 'è¶…å‚æ•°æ•æ„Ÿ'],
                'best_for': 'å¤§é‡æ•°æ®ï¼Œå¤æ‚éçº¿æ€§æ¨¡å¼'
            },
            'XGBoost': {
                'description': 'æ¢¯åº¦æå‡å†³ç­–æ ‘',
                'pros': ['å¼ºå¤§çš„éçº¿æ€§å»ºæ¨¡', 'ç‰¹å¾é‡è¦æ€§', 'å¤„ç†å¼‚å¸¸å€¼'],
                'cons': ['éœ€è¦ç‰¹å¾å·¥ç¨‹', 'å®¹æ˜“è¿‡æ‹Ÿåˆ', 'ç¼ºä¹æ—¶åºç‰¹æ€§'],
                'best_for': 'æœ‰ä¸°å¯Œç‰¹å¾ï¼Œå­˜åœ¨çªå‘æ€§'
            }
        }

    def recommend_models(self, analysis_results: Dict) -> List[Dict]:
        """åŸºäºåˆ†æç»“æœæ¨èæ¨¡å‹"""
        recommendations = []

        stationarity = analysis_results.get('stationarity', {})
        seasonality = analysis_results.get('seasonality', {})
        outliers = analysis_results.get('outliers', {})

        is_stationary = stationarity.get('is_stationary', False)
        has_seasonality = seasonality.get('has_seasonality', False)
        has_outliers = outliers.get('has_bursts', False)
        data_points = analysis_results.get('data_info', {}).get('total_points', 0)

        # åŸºäºæ•°æ®ç‰¹å¾æ¨èæ¨¡å‹
        if not has_seasonality and not has_outliers:
            if is_stationary:
                recommendations.append({
                    'model': 'ARIMA',
                    'score': 9,
                    'reason': 'æ•°æ®å¹³ç¨³ï¼Œæ— å­£èŠ‚æ€§å’Œå¼‚å¸¸å€¼ï¼ŒARIMAæ¨¡å‹æœ€é€‚åˆ'
                })
            else:
                recommendations.append({
                    'model': 'ARIMA',
                    'score': 7,
                    'reason': 'éœ€è¦å·®åˆ†å¤„ç†åä½¿ç”¨ARIMAæ¨¡å‹'
                })

        if has_seasonality:
            recommendations.append({
                'model': 'SARIMA',
                'score': 8,
                'reason': 'å­˜åœ¨å­£èŠ‚æ€§æ¨¡å¼ï¼ŒSARIMAæ¨¡å‹èƒ½å¾ˆå¥½å¤„ç†'
            })

            if data_points > 365:
                recommendations.append({
                    'model': 'Prophet',
                    'score': 8,
                    'reason': 'æ•°æ®é‡å……è¶³ä¸”æœ‰å­£èŠ‚æ€§ï¼ŒProphetè¡¨ç°ä¼˜ç§€'
                })

        if has_outliers:
            recommendations.append({
                'model': 'Prophet',
                'score': 8,
                'reason': 'å¯¹å¼‚å¸¸å€¼å…·æœ‰é²æ£’æ€§'
            })

            recommendations.append({
                'model': 'XGBoost',
                'score': 7,
                'reason': 'èƒ½å¤Ÿå¤„ç†å¼‚å¸¸å€¼å’Œéçº¿æ€§å…³ç³»'
            })

        if data_points > 1000:
            recommendations.append({
                'model': 'LSTM',
                'score': 7,
                'reason': 'æ•°æ®é‡å……è¶³ï¼Œå¯ä»¥å°è¯•æ·±åº¦å­¦ä¹ æ–¹æ³•'
            })

        # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªæ¨è
        if not recommendations:
            recommendations.append({
                'model': 'ARIMA',
                'score': 6,
                'reason': 'é€šç”¨çš„æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•'
            })

        # æŒ‰åˆ†æ•°æ’åºå¹¶æ·»åŠ è¯¦ç»†ä¿¡æ¯
        recommendations.sort(key=lambda x: x['score'], reverse=True)
        for rec in recommendations:
            rec.update(self.model_info.get(rec['model'], {}))

        return recommendations


# --- æ•°æ®ç”Ÿæˆå™¨ç±» ---
class DataGenerator:
    """æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨"""

    @staticmethod
    def generate_epidemic_data(
            start_date: str = '2020-01-01',
            periods: int = 1095,  # 3å¹´
            base_level: float = 100,
            noise_level: float = 10,
            seasonal_amplitude: float = 50,
            outbreak_params: Optional[Dict] = None
    ) -> pd.DataFrame:
        """ç”Ÿæˆæ›´çœŸå®çš„ä¼ æŸ“ç—…æ•°æ®"""

        dates = pd.date_range(start=start_date, periods=periods, freq='D')

        # åŸºç¡€æ°´å¹³ï¼ˆå¸¦è¶‹åŠ¿ï¼‰
        trend = np.linspace(0, 20, periods)
        base_data = base_level + trend + np.random.normal(0, noise_level, periods)

        # å­£èŠ‚æ€§æˆåˆ†ï¼ˆå¹´åº¦å’Œå‘¨åº¦ï¼‰
        yearly_seasonal = seasonal_amplitude * np.sin(2 * np.pi * np.arange(periods) / 365.25 + np.pi / 2)
        weekly_seasonal = 10 * np.sin(2 * np.pi * np.arange(periods) / 7)

        # çªå‘ç–«æƒ…
        outbreak_data = np.zeros(periods)
        if outbreak_params:
            start_day = outbreak_params.get('start_day', 400)
            duration = outbreak_params.get('duration', 60)
            intensity = outbreak_params.get('intensity', 200)

            if start_day < periods:
                end_day = min(start_day + duration, periods)
                outbreak_pattern = intensity * np.exp(-0.1 * np.arange(duration))
                outbreak_data[start_day:start_day + len(outbreak_pattern)] = outbreak_pattern[:end_day - start_day]

        # ç»„åˆæ‰€æœ‰æˆåˆ†
        total_cases = base_data + yearly_seasonal + weekly_seasonal + outbreak_data
        total_cases = np.maximum(total_cases, 0)  # ç¡®ä¿éè´Ÿ
        total_cases = np.round(total_cases).astype(int)

        df = pd.DataFrame({
            'Date': dates,
            'Cases': total_cases
        })

        return df


# --- å¯è§†åŒ–ç±» ---
class Visualizer:
    """æ•°æ®å¯è§†åŒ–ç±»"""

    @staticmethod
    def plot_time_series(df: pd.DataFrame, title: str = "æ—¶é—´åºåˆ—æ•°æ®") -> go.Figure:
        """ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾"""
        fig = go.Figure()

        fig.add_trace(go.Scatter(
            x=df['Date'],
            y=df['Cases'],
            mode='lines',
            name='ç—…ä¾‹æ•°',
            line=dict(color='blue', width=2)
        ))

        fig.update_layout(
            title=title,
            xaxis_title='æ—¥æœŸ',
            yaxis_title='ç—…ä¾‹æ•°',
            hovermode='x unified',
            showlegend=True
        )

        return fig

    @staticmethod
    def plot_forecast_comparison(historical_df: pd.DataFrame, forecast_df: pd.DataFrame) -> go.Figure:
        """ç»˜åˆ¶å†å²æ•°æ®å’Œé¢„æµ‹ç»“æœå¯¹æ¯”å›¾"""
        fig = go.Figure()

        # å†å²æ•°æ®
        fig.add_trace(go.Scatter(
            x=historical_df['Date'],
            y=historical_df['Cases'],
            mode='lines',
            name='å†å²æ•°æ®',
            line=dict(color='blue', width=2)
        ))

        # é¢„æµ‹æ•°æ®
        fig.add_trace(go.Scatter(
            x=forecast_df['Date'],
            y=forecast_df['PredictedCases'],
            mode='lines',
            name='é¢„æµ‹æ•°æ®',
            line=dict(color='red', width=2, dash='dash')
        ))

        fig.update_layout(
            title='å†å²æ•°æ®ä¸é¢„æµ‹ç»“æœå¯¹æ¯”',
            xaxis_title='æ—¥æœŸ',
            yaxis_title='ç—…ä¾‹æ•°',
            hovermode='x unified',
            showlegend=True
        )

        return fig


# --- ä¸»åº”ç”¨ç±» ---
class EpidemicPredictionApp:
    """ä¸»åº”ç”¨ç±»"""

    def __init__(self):
        self.init_session_state()
        self.analyzer = TimeSeriesAnalyzer()
        self.recommender = ModelRecommender()
        self.visualizer = Visualizer()

    def init_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        default_states = {
            'current_step': 0,
            'uploaded_data': None,
            'analysis_results': None,
            'recommended_models': [],
            'selected_model': '',
            'training_results': None,
            'privacy_status': '',
            'forecast_results': None,
            'processed_data': None
        }

        for key, value in default_states.items():
            if key not in st.session_state:
                st.session_state[key] = value

    def setup_page(self):
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            layout="wide",
            page_title="ä¼ æŸ“ç—…äººæ•°é¢„æµ‹ç³»ç»Ÿ",
            page_icon="ğŸ¦ ",
            initial_sidebar_state="expanded"
        )

        st.title("ğŸ¦  ä¼ æŸ“ç—…äººæ•°é¢„æµ‹ç³»ç»Ÿ")
        st.markdown("---")

    def render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        steps = [
            "ğŸ“ æ•°æ®ä¸Šä¼ ",
            "ğŸ“Š æ•°æ®åˆ†æ",
            "ğŸ¤– æ¨¡å‹æ¨è",
            "âš™ï¸ æ¨¡å‹è®­ç»ƒ",
            "ğŸ”’ éšç§ä¿æŠ¤",
            "ğŸ“ˆ ç»“æœè¾“å‡º"
        ]

        st.sidebar.header("ğŸ§­ å¯¼èˆª")

        for i, step_name in enumerate(steps):
            is_accessible = i <= st.session_state.current_step
            is_current = i == st.session_state.current_step

            if st.sidebar.button(
                    f"{step_name}",
                    disabled=not is_accessible,
                    key=f"nav_btn_{i}",
                    type="primary" if is_current else "secondary"
            ):
                st.session_state.current_step = i
                st.rerun()

        st.sidebar.markdown("---")
        st.sidebar.info("ğŸ’¡ è¯·æŒ‰ç…§æ­¥éª¤é¡ºåºæ“ä½œ")

        # æ˜¾ç¤ºå½“å‰æ•°æ®çŠ¶æ€
        if st.session_state.uploaded_data is not None:
            st.sidebar.success(f"âœ… å·²åŠ è½½ {len(st.session_state.uploaded_data)} æ¡è®°å½•")

        if st.session_state.selected_model:
            st.sidebar.info(f"ğŸ¯ å½“å‰æ¨¡å‹: {st.session_state.selected_model}")

    def render_step_0_data_upload(self):
        """æ­¥éª¤0: æ•°æ®ä¸Šä¼ """
        st.header("ğŸ“ ç¬¬ä¸€æ­¥ï¼šæ•°æ®ä¸Šä¼ ")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.write("æ‚¨å¯ä»¥ä¸Šä¼ CSVæˆ–Excelæ–‡ä»¶ï¼Œæˆ–ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤ºã€‚")
            st.info("ğŸ“‹ æ•°æ®è¦æ±‚ï¼šå¿…é¡»åŒ…å« 'Date'ï¼ˆæ—¥æœŸï¼‰å’Œ 'Cases'ï¼ˆç—…ä¾‹æ•°ï¼‰åˆ—")

            uploaded_file = st.file_uploader(
                "é€‰æ‹©æ•°æ®æ–‡ä»¶",
                type=Config.SUPPORTED_FORMATS,
                help="æ”¯æŒCSVå’ŒExcelæ ¼å¼ï¼Œæ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MB"
            )

            if uploaded_file is not None:
                self.process_uploaded_file(uploaded_file)

        with col2:
            st.markdown("### ğŸ§ª æˆ–ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®")

            with st.expander("âš™ï¸ æ¨¡æ‹Ÿæ•°æ®å‚æ•°"):
                start_date = st.date_input("å¼€å§‹æ—¥æœŸ", pd.to_datetime('2020-01-01'))
                periods = st.slider("æ•°æ®ç‚¹æ•°", 365, 1095, 1095)
                base_level = st.slider("åŸºç¡€ç—…ä¾‹æ•°", 50, 200, 100)
                seasonal_amplitude = st.slider("å­£èŠ‚æ€§å¼ºåº¦", 20, 100, 50)

                add_outbreak = st.checkbox("æ·»åŠ ç–«æƒ…çˆ†å‘", value=True)
                outbreak_params = None
                if add_outbreak:
                    outbreak_day = st.slider("çˆ†å‘å¼€å§‹å¤©æ•°", 100, periods - 100, 400)
                    outbreak_duration = st.slider("çˆ†å‘æŒç»­å¤©æ•°", 30, 120, 60)
                    outbreak_intensity = st.slider("çˆ†å‘å¼ºåº¦", 100, 500, 200)
                    outbreak_params = {
                        'start_day': outbreak_day,
                        'duration': outbreak_duration,
                        'intensity': outbreak_intensity
                    }

            if st.button("ğŸš€ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®", type="primary"):
                self.generate_simulation_data(start_date, periods, base_level, seasonal_amplitude, outbreak_params)

        # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ•°æ®
        if st.session_state.uploaded_data is not None:
            self.display_data_preview()

    def process_uploaded_file(self, uploaded_file):
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        try:
            # éªŒè¯æ–‡ä»¶å¤§å°
            if not DataValidator.validate_file_size(uploaded_file):
                st.error(f"âŒ æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆ{Config.MAX_FILE_SIZE / 1024 / 1024:.0f}MBï¼‰")
                return

            # è¯»å–æ–‡ä»¶
            with st.spinner("ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶..."):
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file, encoding='utf-8')
                else:
                    df = pd.read_excel(uploaded_file)

            # éªŒè¯æ•°æ®ç»“æ„
            is_valid, message = DataValidator.validate_data_structure(df)
            if not is_valid:
                st.error(f"âŒ {message}")
                return

            # è§£ææ—¥æœŸ
            df = DataValidator.parse_date_column(df)

            # æ¸…æ´—æ•°æ®
            df = DataValidator.clean_data(df)

            st.session_state.uploaded_data = df
            st.session_state.current_step = 1
            st.success("âœ… æ•°æ®æ–‡ä»¶å·²æˆåŠŸä¸Šä¼ å¹¶éªŒè¯ï¼")
            st.rerun()

        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            st.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")

    def generate_simulation_data(self, start_date, periods, base_level, seasonal_amplitude, outbreak_params):
        """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
        try:
            with st.spinner("ğŸ§ª æ­£åœ¨ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®..."):
                df = DataGenerator.generate_epidemic_data(
                    start_date=start_date.strftime('%Y-%m-%d'),
                    periods=periods,
                    base_level=base_level,
                    seasonal_amplitude=seasonal_amplitude,
                    outbreak_params=outbreak_params
                )

                st.session_state.uploaded_data = df
                st.session_state.current_step = 1
                st.success("âœ… æ¨¡æ‹Ÿæ•°æ®å·²æˆåŠŸç”Ÿæˆï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
            st.error(f"âŒ æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå¤±è´¥: {str(e)}")

    def display_data_preview(self):
        """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
        st.markdown("### ğŸ“‹ æ•°æ®é¢„è§ˆ")

        col1, col2 = st.columns([2, 1])

        with col1:
            st.dataframe(
                st.session_state.uploaded_data.head(10),
                use_container_width=True
            )

        with col2:
            df = st.session_state.uploaded_data
            st.metric("æ•°æ®ç‚¹æ•°", len(df))
            st.metric("æ—¥æœŸèŒƒå›´", f"{df['Date'].min()} è‡³ {df['Date'].max()}")
            st.metric("å¹³å‡ç—…ä¾‹æ•°", f"{df['Cases'].mean():.1f}")

        # ç»˜åˆ¶æ—¶é—´åºåˆ—å›¾
        try:
            fig = self.visualizer.plot_time_series(st.session_state.uploaded_data)
            st.plotly_chart(fig, use_container_width=True)
        except Exception as e:
            st.warning(f"âš ï¸ æ— æ³•ç»˜åˆ¶å›¾è¡¨: {str(e)}")

    def render_step_1_data_analysis(self):
        """æ­¥éª¤1: æ•°æ®åˆ†æ"""
        st.header("ğŸ“Š ç¬¬äºŒæ­¥ï¼šæ•°æ®åˆ†æ")

        if st.session_state.uploaded_data is None:
            st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®")
            return

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("ç³»ç»Ÿå°†åˆ†ææ•°æ®çš„ç»Ÿè®¡ç‰¹æ€§ï¼ŒåŒ…æ‹¬å¹³ç¨³æ€§ã€å­£èŠ‚æ€§å’Œå¼‚å¸¸å€¼æ£€æµ‹ã€‚")

        with col2:
            if st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
                self.perform_data_analysis()

        # æ˜¾ç¤ºåˆ†æç»“æœ
        if st.session_state.analysis_results is not None:
            self.display_analysis_results()

    def perform_data_analysis(self):
        """æ‰§è¡Œæ•°æ®åˆ†æ"""
        try:
            with st.spinner("ğŸ” æ­£åœ¨æ‰§è¡Œæ•°æ®åˆ†æ..."):
                results = self.analyzer.comprehensive_analysis(st.session_state.uploaded_data)
                st.session_state.analysis_results = results
                st.session_state.current_step = 2
                st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"æ•°æ®åˆ†æå¤±è´¥: {e}")
            st.error(f"âŒ æ•°æ®åˆ†æå¤±è´¥: {str(e)}")

    def display_analysis_results(self):
        """æ˜¾ç¤ºåˆ†æç»“æœ"""
        results = st.session_state.analysis_results

        if 'error' in results:
            st.error(f"âŒ åˆ†æå¤±è´¥: {results['error']}")
            return

        st.markdown("### ğŸ“ˆ åˆ†æç»“æœ")

        # æ•°æ®åŸºæœ¬ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)

        data_info = results.get('data_info', {})
        with col1:
            st.metric("æ•°æ®ç‚¹æ•°", data_info.get('total_points', 'N/A'))
        with col2:
            st.metric("å¹³å‡ç—…ä¾‹æ•°", f"{data_info.get('mean_cases', 0):.1f}")
        with col3:
            st.metric("æœ€å¤§ç—…ä¾‹æ•°", data_info.get('max_cases', 'N/A'))
        with col4:
            st.metric("æ ‡å‡†å·®", f"{data_info.get('std_cases', 0):.1f}")

        # è¯¦ç»†åˆ†æç»“æœ
        col1, col2, col3 = st.columns(3)

        with col1:
            st.markdown("#### ğŸ¯ å¹³ç¨³æ€§æ£€æµ‹")
            stationarity = results.get('stationarity', {})
            if 'error' not in stationarity:
                st.write(f"**ç»“æœ**: {stationarity.get('interpretation', 'N/A')}")
                st.write(f"**På€¼**: {stationarity.get('p_value', 0):.4f}")
                st.write(f"**æ£€éªŒç»Ÿè®¡é‡**: {stationarity.get('adf_statistic', 0):.4f}")
            else:
                st.error(f"æ£€æµ‹å¤±è´¥: {stationarity['error']}")

        with col2:
            st.markdown("#### ğŸ”„ å­£èŠ‚æ€§æ£€æµ‹")
            seasonality = results.get('seasonality', {})
            if 'error' not in seasonality:
                st.write(f"**ç»“æœ**: {seasonality.get('interpretation', 'N/A')}")
                if 'seasonal_strength' in seasonality:
                    st.write(f"**å­£èŠ‚æ€§å¼ºåº¦**: {seasonality['seasonal_strength']:.4f}")
                if 'warning' in seasonality:
                    st.warning(seasonality['warning'])
            else:
                st.error(f"æ£€æµ‹å¤±è´¥: {seasonality['error']}")

        with col3:
            st.markdown("#### âš¡ å¼‚å¸¸å€¼æ£€æµ‹")
            outliers = results.get('outliers', {})
            if 'error' not in outliers:
                st.write(f"**ç»“æœ**: {outliers.get('interpretation', 'N/A')}")
                st.write(f"**å¼‚å¸¸å€¼æ•°é‡**: {outliers.get('num_outliers', 0)}")
                st.write(f"**å¼‚å¸¸å€¼æ¯”ä¾‹**: {outliers.get('outlier_percentage', 0):.2f}%")
            else:
                st.error(f"æ£€æµ‹å¤±è´¥: {outliers['error']}")

        # ç»¼åˆæ‘˜è¦
        st.markdown("#### ğŸ“ ç»¼åˆæ‘˜è¦")
        st.info(results.get('summary', 'æ— æ³•ç”Ÿæˆæ‘˜è¦'))

    def render_step_2_model_recommendation(self):
        """æ­¥éª¤2: æ¨¡å‹æ¨è"""
        st.header("ğŸ¤– ç¬¬ä¸‰æ­¥ï¼šæ¨¡å‹æ¨è")

        if st.session_state.analysis_results is None:
            st.warning("âš ï¸ è¯·å…ˆå®Œæˆæ•°æ®åˆ†æ")
            return

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("åŸºäºæ•°æ®åˆ†æç»“æœï¼Œç³»ç»Ÿå°†æ¨èæœ€é€‚åˆçš„é¢„æµ‹æ¨¡å‹ã€‚")

        with col2:
            if st.button("ğŸ¯ è·å–æ¨è", type="primary"):
                self.get_model_recommendations()

        # æ˜¾ç¤ºæ¨èç»“æœ
        if st.session_state.recommended_models:
            self.display_model_recommendations()

    def get_model_recommendations(self):
        """è·å–æ¨¡å‹æ¨è"""
        try:
            with st.spinner("ğŸ¤– æ­£åœ¨åˆ†æå¹¶æ¨èæ¨¡å‹..."):
                recommendations = self.recommender.recommend_models(st.session_state.analysis_results)
                st.session_state.recommended_models = recommendations
                st.session_state.selected_model = recommendations[0]['model'] if recommendations else ''
                st.session_state.current_step = 3
                st.success("âœ… æ¨¡å‹æ¨èå®Œæˆï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"æ¨¡å‹æ¨èå¤±è´¥: {e}")
            st.error(f"âŒ æ¨¡å‹æ¨èå¤±è´¥: {str(e)}")

    def display_model_recommendations(self):
        """æ˜¾ç¤ºæ¨¡å‹æ¨è"""
        st.markdown("### ğŸ† æ¨èæ¨¡å‹")

        # æ˜¾ç¤ºå‰3ä¸ªæ¨è
        for i, rec in enumerate(st.session_state.recommended_models[:3]):
            with st.expander(f"#{i + 1} {rec['model']} (æ¨èåˆ†æ•°: {rec['score']}/10)", expanded=(i == 0)):
                col1, col2 = st.columns([2, 1])

                with col1:
                    st.write(f"**æè¿°**: {rec.get('description', 'N/A')}")
                    st.write(f"**æ¨èç†ç”±**: {rec.get('reason', 'N/A')}")
                    st.write(f"**é€‚ç”¨åœºæ™¯**: {rec.get('best_for', 'N/A')}")

                with col2:
                    if rec.get('pros'):
                        st.write("**ä¼˜ç‚¹**:")
                        for pro in rec['pros']:
                            st.write(f"â€¢ {pro}")

                    if rec.get('cons'):
                        st.write("**ç¼ºç‚¹**:")
                        for con in rec['cons']:
                            st.write(f"â€¢ {con}")

        # æ¨¡å‹é€‰æ‹©
        st.markdown("### ğŸ›ï¸ é€‰æ‹©æ¨¡å‹")
        model_options = [rec['model'] for rec in st.session_state.recommended_models]

        selected_model = st.selectbox(
            "è¯·é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹:",
            model_options,
            index=model_options.index(
                st.session_state.selected_model) if st.session_state.selected_model in model_options else 0
        )

        st.session_state.selected_model = selected_model

        if st.button("âœ… ç¡®è®¤é€‰æ‹©", type="primary"):
            st.success(f"âœ… å·²é€‰æ‹©æ¨¡å‹: {selected_model}")
            st.session_state.current_step = 3

    def render_step_3_model_training(self):
        """æ­¥éª¤3: æ¨¡å‹è®­ç»ƒ"""
        st.header("âš™ï¸ ç¬¬å››æ­¥ï¼šæ¨¡å‹è®­ç»ƒä¸è°ƒå‚")

        if not st.session_state.selected_model:
            st.warning("âš ï¸ è¯·å…ˆé€‰æ‹©æ¨¡å‹")
            return

        col1, col2 = st.columns([3, 1])

        with col1:
            st.info(f"ğŸ¯ å½“å‰é€‰æ‹©çš„æ¨¡å‹: **{st.session_state.selected_model}**")
            st.write("ç³»ç»Ÿå°†è‡ªåŠ¨è¿›è¡Œæ¨¡å‹è®­ç»ƒå’Œè¶…å‚æ•°ä¼˜åŒ–ã€‚")

        with col2:
            if st.button("ğŸš€ å¼€å§‹è®­ç»ƒ", type="primary"):
                self.train_model()

        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        if st.session_state.training_results:
            self.display_training_results()

    def train_model(self):
        """æ¨¡æ‹Ÿæ¨¡å‹è®­ç»ƒ"""
        try:
            with st.spinner("ğŸ”„ æ­£åœ¨è®­ç»ƒæ¨¡å‹..."):
                # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
                import time
                time.sleep(2)

                # æ ¹æ®æ¨¡å‹ç±»å‹ç”Ÿæˆä¸åŒçš„ç»“æœ
                model_name = st.session_state.selected_model

                training_results = {
                    'status': f'æ¨¡å‹ {model_name} è®­ç»ƒå®Œæˆ',
                    'model_type': model_name,
                    'training_time': '2.3ç§’ï¼ˆæ¨¡æ‹Ÿï¼‰',
                    'best_params': self._get_mock_params(model_name),
                    'performance_metrics': self._get_mock_performance(model_name),
                    'validation_scores': {
                        'train_score': 0.92,
                        'validation_score': 0.87,
                        'test_score': 0.85
                    }
                }

                st.session_state.training_results = training_results
                st.session_state.current_step = 4
                st.success("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            st.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")

    def _get_mock_params(self, model_name: str) -> Dict:
        """è·å–æ¨¡æ‹Ÿçš„æœ€ä½³å‚æ•°"""
        params_map = {
            'ARIMA': {'p': 2, 'd': 1, 'q': 1},
            'SARIMA': {'p': 1, 'd': 1, 'q': 1, 'P': 0, 'D': 1, 'Q': 1, 's': 365},
            'Prophet': {'changepoint_prior_scale': 0.05, 'seasonality_prior_scale': 10.0},
            'LSTM': {'epochs': 100, 'batch_size': 32, 'layers': 2, 'units': 50},
            'XGBoost': {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1}
        }
        return params_map.get(model_name, {'param1': 'value1'})

    def _get_mock_performance(self, model_name: str) -> Dict:
        """è·å–æ¨¡æ‹Ÿçš„æ€§èƒ½æŒ‡æ ‡"""
        performance_map = {
            'ARIMA': {'RMSE': 15.2, 'MAE': 12.1, 'MAPE': 0.08},
            'SARIMA': {'RMSE': 12.8, 'MAE': 10.5, 'MAPE': 0.06},
            'Prophet': {'RMSE': 14.1, 'MAE': 11.2, 'MAPE': 0.07},
            'LSTM': {'RMSE': 18.5, 'MAE': 14.8, 'MAPE': 0.10},
            'XGBoost': {'RMSE': 16.0, 'MAE': 13.2, 'MAPE': 0.09}
        }
        return performance_map.get(model_name, {'RMSE': 17.0, 'MAPE': 0.095})

    def display_training_results(self):
        """æ˜¾ç¤ºè®­ç»ƒç»“æœ"""
        results = st.session_state.training_results

        st.markdown("### ğŸ“Š è®­ç»ƒç»“æœ")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric("è®­ç»ƒæ—¶é—´", results['training_time'])
        with col2:
            st.metric("è®­ç»ƒåˆ†æ•°", f"{results['validation_scores']['train_score']:.3f}")
        with col3:
            st.metric("éªŒè¯åˆ†æ•°", f"{results['validation_scores']['validation_score']:.3f}")

        # æœ€ä½³å‚æ•°
        st.markdown("#### ğŸ›ï¸ æœ€ä½³è¶…å‚æ•°")
        st.json(results['best_params'])

        # æ€§èƒ½æŒ‡æ ‡
        st.markdown("#### ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡")
        metrics = results['performance_metrics']

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("RMSE", f"{metrics.get('RMSE', 0):.2f}")
        with col2:
            st.metric("MAE", f"{metrics.get('MAE', 0):.2f}")
        with col3:
            st.metric("MAPE", f"{metrics.get('MAPE', 0):.3f}")

    def render_step_4_privacy_protection(self):
        """æ­¥éª¤4: éšç§ä¿æŠ¤"""
        st.header("ğŸ”’ ç¬¬äº”æ­¥ï¼šéšç§ä¿æŠ¤")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("ç³»ç»Ÿå°†å¯¹æ•°æ®å’Œæ¨¡å‹åº”ç”¨éšç§ä¿æŠ¤æªæ–½ã€‚")

            # éšç§ä¿æŠ¤é€‰é¡¹
            privacy_options = st.multiselect(
                "é€‰æ‹©éšç§ä¿æŠ¤æªæ–½:",
                [
                    "æ•°æ®è„±æ•",
                    "å·®åˆ†éšç§",
                    "è”é‚¦å­¦ä¹ ",
                    "åŒæ€åŠ å¯†"
                ],
                default=["æ•°æ®è„±æ•", "å·®åˆ†éšç§"]
            )

        with col2:
            if st.button("ğŸ›¡ï¸ åº”ç”¨ä¿æŠ¤", type="primary"):
                self.apply_privacy_protection(privacy_options)

        # æ˜¾ç¤ºéšç§ä¿æŠ¤çŠ¶æ€
        if st.session_state.privacy_status:
            st.success(st.session_state.privacy_status)

    def apply_privacy_protection(self, options: List[str]):
        """åº”ç”¨éšç§ä¿æŠ¤"""
        try:
            with st.spinner("ğŸ›¡ï¸ æ­£åœ¨åº”ç”¨éšç§ä¿æŠ¤æªæ–½..."):
                import time
                time.sleep(1)

                applied_measures = ", ".join(options) if options else "åŸºç¡€ä¿æŠ¤"
                status = f"âœ… å·²åº”ç”¨éšç§ä¿æŠ¤æªæ–½: {applied_measures}"

                st.session_state.privacy_status = status
                st.session_state.current_step = 5
                st.success("âœ… éšç§ä¿æŠ¤æªæ–½å·²åº”ç”¨ï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"éšç§ä¿æŠ¤å¤±è´¥: {e}")
            st.error(f"âŒ éšç§ä¿æŠ¤å¤±è´¥: {str(e)}")

    def render_step_5_results_output(self):
        """æ­¥éª¤5: ç»“æœè¾“å‡º"""
        st.header("ğŸ“ˆ ç¬¬å…­æ­¥ï¼šç»“æœè¾“å‡º")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("ç”Ÿæˆé¢„æµ‹ç»“æœå¹¶è¿›è¡Œå¯è§†åŒ–å±•ç¤ºã€‚")

            # é¢„æµ‹å‚æ•°è®¾ç½®
            forecast_days = st.slider("é¢„æµ‹å¤©æ•°", 7, 90, 30)
            confidence_interval = st.slider("ç½®ä¿¡åŒºé—´", 80, 99, 95)

        with col2:
            if st.button("ğŸ“Š ç”Ÿæˆé¢„æµ‹", type="primary"):
                self.generate_predictions(forecast_days, confidence_interval)

        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        if st.session_state.forecast_results is not None:
            self.display_forecast_results()

    def generate_predictions(self, forecast_days: int, confidence_interval: int):
        """ç”Ÿæˆé¢„æµ‹ç»“æœ"""
        try:
            with st.spinner("ğŸ”® æ­£åœ¨ç”Ÿæˆé¢„æµ‹ç»“æœ..."):
                df = st.session_state.uploaded_data
                model_name = st.session_state.selected_model

                # æ¨¡æ‹Ÿé¢„æµ‹è¿‡ç¨‹
                last_date = pd.to_datetime(df['Date'].max())
                future_dates = pd.date_range(
                    start=last_date + pd.Timedelta(days=1),
                    periods=forecast_days,
                    freq='D'
                )

                # æ ¹æ®æ¨¡å‹ç±»å‹ç”Ÿæˆä¸åŒçš„é¢„æµ‹ç»“æœ
                last_value = df['Cases'].iloc[-1]

                if model_name in ['Prophet', 'SARIMA']:
                    # å¸¦å­£èŠ‚æ€§çš„é¢„æµ‹
                    trend = np.linspace(0, forecast_days * 0.1, forecast_days)
                    seasonal = 20 * np.sin(2 * np.pi * np.arange(forecast_days) / 365.25)
                    noise = np.random.normal(0, 5, forecast_days)
                    predictions = last_value + trend + seasonal + noise
                else:
                    # ç®€å•è¶‹åŠ¿é¢„æµ‹
                    trend = np.linspace(0, forecast_days * 0.05, forecast_days)
                    noise = np.random.normal(0, 8, forecast_days)
                    predictions = last_value + trend + noise

                predictions = np.maximum(predictions, 0).round().astype(int)

                # ç”Ÿæˆç½®ä¿¡åŒºé—´
                margin = predictions * 0.15  # 15%çš„è¯¯å·®èŒƒå›´
                upper_bound = (predictions + margin).round().astype(int)
                lower_bound = np.maximum(predictions - margin, 0).round().astype(int)

                forecast_df = pd.DataFrame({
                    'Date': future_dates,
                    'PredictedCases': predictions,
                    'UpperBound': upper_bound,
                    'LowerBound': lower_bound,
                    'ConfidenceInterval': confidence_interval
                })

                st.session_state.forecast_results = forecast_df
                st.success("âœ… é¢„æµ‹ç»“æœå·²ç”Ÿæˆï¼")
                st.rerun()

        except Exception as e:
            logger.error(f"é¢„æµ‹ç”Ÿæˆå¤±è´¥: {e}")
            st.error(f"âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥: {str(e)}")

    def display_forecast_results(self):
        """æ˜¾ç¤ºé¢„æµ‹ç»“æœ"""
        st.markdown("### ğŸ”® é¢„æµ‹ç»“æœ")

        forecast_df = st.session_state.forecast_results

        # é¢„æµ‹æ‘˜è¦
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("é¢„æµ‹å¤©æ•°", len(forecast_df))
        with col2:
            st.metric("å¹³å‡é¢„æµ‹å€¼", f"{forecast_df['PredictedCases'].mean():.1f}")
        with col3:
            st.metric("æœ€å¤§é¢„æµ‹å€¼", forecast_df['PredictedCases'].max())
        with col4:
            st.metric("æœ€å°é¢„æµ‹å€¼", forecast_df['PredictedCases'].min())

        # é¢„æµ‹ç»“æœè¡¨æ ¼
        st.markdown("#### ğŸ“‹ é¢„æµ‹æ•°æ®")
        st.dataframe(
            forecast_df[['Date', 'PredictedCases', 'LowerBound', 'UpperBound']],
            use_container_width=True
        )

        # å¯è§†åŒ–å›¾è¡¨
        st.markdown("#### ğŸ“Š é¢„æµ‹å¯è§†åŒ–")
        self.plot_forecast_with_confidence()

        # ä¸‹è½½é€‰é¡¹
        st.markdown("#### ğŸ’¾ ä¸‹è½½ç»“æœ")
        col1, col2 = st.columns(2)

        with col1:
            csv = forecast_df.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½CSV",
                data=csv,
                file_name=f"forecast_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

        with col2:
            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            st.download_button(
                label="ğŸ“„ ä¸‹è½½æŠ¥å‘Š",
                data=report,
                file_name=f"prediction_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime="text/plain"
            )

    def plot_forecast_with_confidence(self):
        """ç»˜åˆ¶å¸¦ç½®ä¿¡åŒºé—´çš„é¢„æµ‹å›¾"""
        try:
            historical_df = st.session_state.uploaded_data
            forecast_df = st.session_state.forecast_results

            fig = go.Figure()

            # å†å²æ•°æ®
            fig.add_trace(go.Scatter(
                x=historical_df['Date'],
                y=historical_df['Cases'],
                mode='lines',
                name='å†å²æ•°æ®',
                line=dict(color='blue', width=2)
            ))

            # é¢„æµ‹æ•°æ®
            fig.add_trace(go.Scatter(
                x=forecast_df['Date'],
                y=forecast_df['PredictedCases'],
                mode='lines',
                name='é¢„æµ‹æ•°æ®',
                line=dict(color='red', width=2)
            ))

            # ç½®ä¿¡åŒºé—´
            fig.add_trace(go.Scatter(
                x=forecast_df['Date'],
                y=forecast_df['UpperBound'],
                mode='lines',
                line=dict(width=0),
                showlegend=False,
                hoverinfo='skip'
            ))

            fig.add_trace(go.Scatter(
                x=forecast_df['Date'],
                y=forecast_df['LowerBound'],
                mode='lines',
                line=dict(width=0),
                fillcolor='rgba(255,0,0,0.2)',
                fill='tonexty',
                name=f"{forecast_df['ConfidenceInterval'].iloc[0]}% ç½®ä¿¡åŒºé—´",
                hoverinfo='skip'
            ))

            fig.update_layout(
                title='å†å²æ•°æ®ä¸é¢„æµ‹ç»“æœï¼ˆå«ç½®ä¿¡åŒºé—´ï¼‰',
                xaxis_title='æ—¥æœŸ',
                yaxis_title='ç—…ä¾‹æ•°',
                hovermode='x unified',
                showlegend=True,
                height=500
            )

            st.plotly_chart(fig, use_container_width=True)

        except Exception as e:
            logger.error(f"ç»˜å›¾å¤±è´¥: {e}")
            st.error(f"âŒ ç»˜å›¾å¤±è´¥: {str(e)}")

    def generate_report(self) -> str:
        """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
        try:
            report_lines = [
                "=" * 50,
                "ä¼ æŸ“ç—…äººæ•°é¢„æµ‹æŠ¥å‘Š",
                "=" * 50,
                f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                "",
                "1. æ•°æ®æ¦‚å†µ",
                "-" * 20
            ]

            if st.session_state.uploaded_data is not None:
                df = st.session_state.uploaded_data
                report_lines.extend([
                    f"æ•°æ®ç‚¹æ•°: {len(df)}",
                    f"æ—¥æœŸèŒƒå›´: {df['Date'].min()} è‡³ {df['Date'].max()}",
                    f"å¹³å‡ç—…ä¾‹æ•°: {df['Cases'].mean():.2f}",
                    f"æœ€å¤§ç—…ä¾‹æ•°: {df['Cases'].max()}",
                    f"æœ€å°ç—…ä¾‹æ•°: {df['Cases'].min()}",
                    ""
                ])

            if st.session_state.analysis_results:
                report_lines.extend([
                    "2. æ•°æ®åˆ†æç»“æœ",
                    "-" * 20,
                    st.session_state.analysis_results.get('summary', 'æ— æ‘˜è¦'),
                    ""
                ])

            if st.session_state.selected_model:
                report_lines.extend([
                    "3. æ¨¡å‹ä¿¡æ¯",
                    "-" * 20,
                    f"é€‰æ‹©çš„æ¨¡å‹: {st.session_state.selected_model}",
                    ""
                ])

            if st.session_state.forecast_results is not None:
                forecast_df = st.session_state.forecast_results
                report_lines.extend([
                    "4. é¢„æµ‹ç»“æœ",
                    "-" * 20,
                    f"é¢„æµ‹å¤©æ•°: {len(forecast_df)}",
                    f"å¹³å‡é¢„æµ‹å€¼: {forecast_df['PredictedCases'].mean():.2f}",
                    f"é¢„æµ‹èŒƒå›´: {forecast_df['PredictedCases'].min()} - {forecast_df['PredictedCases'].max()}",
                    ""
                ])

            report_lines.extend([
                "5. å…è´£å£°æ˜",
                "-" * 20,
                "æœ¬é¢„æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œå®é™…æƒ…å†µå¯èƒ½å› å¤šç§å› ç´ è€Œå¼‚ã€‚",
                "è¯·ç»“åˆä¸“ä¸šåˆ¤æ–­å’Œå®æ—¶æ•°æ®è¿›è¡Œå†³ç­–ã€‚",
                "=" * 50
            ])

            return "\n".join(report_lines)

        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"

    def run(self):
        """è¿è¡Œåº”ç”¨"""
        self.setup_page()
        self.render_sidebar()

        # æ ¹æ®å½“å‰æ­¥éª¤æ¸²æŸ“å¯¹åº”é¡µé¢
        step_methods = [
            self.render_step_0_data_upload,
            self.render_step_1_data_analysis,
            self.render_step_2_model_recommendation,
            self.render_step_3_model_training,
            self.render_step_4_privacy_protection,
            self.render_step_5_results_output
        ]

        current_step = st.session_state.current_step
        if 0 <= current_step < len(step_methods):
            step_methods[current_step]()
        else:
            st.error("âŒ æ— æ•ˆçš„æ­¥éª¤")


# --- ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        app = EpidemicPredictionApp()
        app.run()
    except Exception as e:
        logger.error(f"åº”ç”¨è¿è¡Œå¤±è´¥: {e}")
        st.error(f"âŒ åº”ç”¨è¿è¡Œå¤±è´¥: {str(e)}")
        st.info("è¯·åˆ·æ–°é¡µé¢é‡è¯•")


if __name__ == "__main__":
    main()
